{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark demo : Part II #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_post_row(line):\n",
    "    return re.match('  <row Id=', line) != None\n",
    "\n",
    "row_rdd = sc.textFile('./data/ai.stackexchange.com/Posts.xml') \\\n",
    "    .filter(is_post_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import HTMLParser\n",
    "h = HTMLParser.HTMLParser()\n",
    "\n",
    "def is_first_post(line):\n",
    "    return re.match('  <row Id=\"\\d+\" PostTypeId=\"1\"', line)\n",
    "\n",
    "def extract_body(line):\n",
    "    matches = re.findall('Body=\"(.*?)\"', line)\n",
    "    parsed_text = h.unescape(matches[0])\n",
    "    return parsed_text\n",
    "\n",
    "questions = row_rdd \\\n",
    "    .filter(is_first_post) \\\n",
    "    .map(extract_body) \\\n",
    "    .take(5)\n",
    "    \n",
    "print (\"\\n\"+(\"=\"*80)+\"\\n\\n\").join(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_counts = row_rdd \\\n",
    "    .map(extract_body) \\\n",
    "    .flatMap(lambda line: [word.lower() for word in re.findall('\\w+', line)]) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey(lambda x, y: x+y) \\\n",
    "    .map(lambda (word, count): (count, word)) \\\n",
    "    .sortByKey(ascending=False) \\\n",
    "    .map(lambda (count, word): (word, count)) \\\n",
    "    .take(50)\n",
    "    \n",
    "for wc in word_counts[10:]:\n",
    "    print wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_favorite_count(row):\n",
    "    matches = re.findall('FavoriteCount=\"(\\d+)\"', row)\n",
    "    if len(matches) > 0:\n",
    "        return int(matches[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "row_rdd \\\n",
    "    .filter(is_first_post) \\\n",
    "    .map(extract_favorite_count) \\\n",
    "    .map(lambda x: (x,1)) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .sortByKey(ascending=True) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rdd_word_count(rdd):\n",
    "    return rdd \\\n",
    "        .map(extract_body) \\\n",
    "        .flatMap(lambda line: [word.lower() for word in re.findall('\\w+', line)]) \\\n",
    "        .map(lambda word: (word, 1)) \\\n",
    "        .reduceByKey(lambda x, y: x+y) \\\n",
    "        .map(lambda (word, count): (count, word)) \\\n",
    "        .sortByKey(ascending=False) \\\n",
    "        .map(lambda (count, word): (word, count)) \\\n",
    "\n",
    "word_counts_from_favorited_posts = get_rdd_word_count(\n",
    "    row_rdd \\\n",
    "        .filter(is_first_post) \\\n",
    "        .filter(lambda x: extract_favorite_count(x)>0)\n",
    ")\n",
    "\n",
    "word_counts_from_nonfavorited_posts = get_rdd_word_count(\n",
    "    row_rdd \\\n",
    "        .filter(is_first_post) \\\n",
    "        .filter(lambda x: extract_favorite_count(x)==0)\n",
    ")\n",
    "\n",
    "word_counts_from_favorited_posts\n",
    "word_counts_from_nonfavorited_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_from_favorited_posts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_words_from_favorited_posts = word_counts_from_favorited_posts \\\n",
    "    .map(lambda x: x[1]) \\\n",
    "    .reduce(lambda x, y: x+y)\n",
    "\n",
    "total_words_from_nonfavorited_posts = word_counts_from_nonfavorited_posts \\\n",
    "    .map(lambda x: x[1]) \\\n",
    "    .reduce(lambda x, y: x+y)\n",
    "    \n",
    "print total_words_from_favorited_posts\n",
    "print total_words_from_nonfavorited_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "log_freq_from_favorite_posts = word_counts_from_favorited_posts.map(lambda x: (x[0], log(x[1]) - log(total_words_from_favorited_posts)))\n",
    "log_freq_from_nonfavorite_posts = word_counts_from_nonfavorited_posts.map(lambda x: (x[0], log(x[1]) - log(total_words_from_nonfavorited_posts)))\n",
    "log_freq_from_favorite_posts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_favorited_words = log_freq_from_favorite_posts \\\n",
    "    .join(log_freq_from_nonfavorite_posts) \\\n",
    "    .map(lambda x: (x[0], x[1][0] - x[1][1])) \\\n",
    "    .map(lambda (word, log_diff): (log_diff, word)) \\\n",
    "    .sortByKey(ascending=False) \\\n",
    "    .take(20)\n",
    "\n",
    "most_favorited_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 1 ###\n",
    "\n",
    "What are the 20 most common words in each of these sets?\n",
    "- Write an RDD to generate counts for all the words that are at least 5 characters long.\n",
    "- Filter this RDD to only include favorited posts.\n",
    "- Filter this RDD to only include posts *without* any favorites.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 ###\n",
    "\n",
    "The logic above creates two separate RDDs for posts with and without favorites, then joins them.\n",
    "\n",
    "There's another way to accomplish the same thing in a single RDD. Hint: you'll need a tuple with (word, count, has_favorites)\n",
    "\n",
    "Generate word counts for favorited posts and non-favorited posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Exercise ###\n",
    "\n",
    "Which post in this data set has the most favorites?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}